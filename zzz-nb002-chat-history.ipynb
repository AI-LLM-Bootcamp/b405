{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Chat Message History\n",
    "* Save list of chat messages and then fetch them all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c759d27a-94f3-4141-945d-065f2095bffd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Intro\n",
    "* Ability to store information about past interactions.\n",
    "* **Most of memory-related functionality in LangChain is marked as beta**. This is for two reasons:\n",
    "    1. Most functionality are not production ready.\n",
    "    2. Most functionality work with Legacy chains, not the newer LCEL syntax.\n",
    "* **The main exception to this is the ChatMessageHistory functionality**. This functionality is largely production ready and does integrate with LCEL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f9501-fa9e-4830-95e2-537dff951cf1",
   "metadata": {},
   "source": [
    "## LangChain documentation on Memory\n",
    "* See the LangChain documentation page on Memory [here](https://python.langchain.com/v0.1/docs/modules/memory/).\n",
    "* See the LangChain documentation page on how to use ChatMessageHistory with LCEL [here](https://python.langchain.com/v0.1/docs/expression_language/how_to/message_history/).\n",
    "* See the LangChain documentation page on the various ChatMessageHistory integrations [here](https://python.langchain.com/v0.1/docs/integrations/memory/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f9bf4-bcc6-4283-b894-0c4dd985f445",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0233ade-b3d9-4dd9-963c-ff8836f4fd5e",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 002-chat-history.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **memory**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46b134-c502-47f1-b67f-c5b03bff1d0a",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fca939-bd83-4d5b-8e34-57cdbe855260",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead3bd7-e4af-45b5-a770-64742c3bca77",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7365e2af-d5f2-481e-9892-babd5f781ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c1af4-733f-4139-9eda-9a546614a3f5",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb4a8e-7d41-40f7-aae7-ca4cd3e4cf21",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e701b3-3e30-4f51-b650-3ea7716c29fe",
   "metadata": {},
   "source": [
    "## ChatMessageHistory\n",
    "* ChatMessageHistory provides convenience methods for saving HumanMessages, AIMessages, and then fetching them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71b9e0b-6c23-4b3d-8713-8e02cedcc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e1a8c0-062d-42f4-abad-4c166e16c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "332d5b3f-02ca-4054-8668-949018b88814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content='whats up?')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71f728-9077-41a0-a9fe-205900742ccc",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 002-chat-memory.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 002-chat-memory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c724f-346a-4013-adee-de5e0f055b32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
